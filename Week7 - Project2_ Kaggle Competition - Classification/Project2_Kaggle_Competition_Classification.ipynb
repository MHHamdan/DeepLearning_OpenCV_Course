{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Project2_Kaggle_Competition_Classification.ipynb","provenance":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3kU7JMWdzSlA"},"source":["# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n","\n","#### Maximum Points: 100\n","\n","<div>\n","    <table>\n","        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n","        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n","        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n","        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n","        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n","        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n","        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n","        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n","        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n","        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n","    </table>\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"Acdtf-YhzSlG"},"source":["## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n","\n","In this section, you have to write a class or methods that will be used to get training and validation data\n","loader.\n","\n","You will have to write a custom dataset class to load data.\n","\n","**Note that there are not separate validation data, so you will have to create your validation set by dividing train data into train and validation data. Usually, in practice, we do `80:20` ratio for train and validation, respectively.** \n","\n","For example,\n","\n","```\n","class KenyanFood13Dataset(Dataset):\n","    \"\"\"\n","    \n","    \"\"\"\n","    \n","    def __init__(self, *args):\n","    ....\n","    ...\n","    \n","    def __getitem__(self, idx):\n","    ...\n","    ...\n","    \n","    \n","```\n","\n","```\n","def get_data(args1, *agrs):\n","    ....\n","    ....\n","    return train_loader, test_loader\n","```"]},{"cell_type":"code","metadata":{"id":"3xo0wASLcjZO","executionInfo":{"status":"ok","timestamp":1610558972655,"user_tz":300,"elapsed":329,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["path = '/content/drive/MyDrive/AI_OpenCV_PyTorch/Week7 - Project2: Kaggle Competition - Classification /dataset/training'"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Dz9uUjWAl4w","executionInfo":{"status":"ok","timestamp":1610558977147,"user_tz":300,"elapsed":4148,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["#import the necessary packages\n","\n","# PyTorch libraries \n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from torchvision.transforms import functional as F_T\n","import torch.nn.functional as F\n","from typing import Iterable\n","from dataclasses import dataclass\n","import matplotlib.pyplot as plt\n","from torch.optim import lr_scheduler\n","from torch.utils.tensorboard import SummaryWriter\n","\n","\n","# file read/write imports\n","import os\n","import numpy as np\n","import pandas as pd\n","import time\n","import csv\n","from PIL import Image\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJOJvkbzy3KM","executionInfo":{"status":"ok","timestamp":1610559153269,"user_tz":300,"elapsed":257,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}}},"source":["# indicate GPU\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n","os.environ[\"CUDA_VISIBLE_DEVICES\"]= '4'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"ImKZSL77gF-J","executionInfo":{"status":"error","timestamp":1609481002570,"user_tz":300,"elapsed":282,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"9efc8d8e-5d02-44ac-fb34-2d3be92d9428"},"source":["class Monkey10Dataset(Dataset):\n","    def __init__(self, mask):\n","        self.mask = mask\n","    def __getitem__(self):\n","        return (self.indices[i] for i in torch.nonzero(self.mask))\n","    def __len__(self):\n","        return len(self.mask)\n","trainset = torchvision.datasets(root=path)\n","train_set = Monkey10Dataset(0.8)\n","test_set = Monkey10Dataset(0.2)\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          sampler = train_set, shuffle=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                          sampler = test_set, shuffle=False, num_workers=2)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-79-30cbe2200d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonkey10Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DlDu3ZMGzSlH","executionInfo":{"status":"ok","timestamp":1609480234394,"user_tz":300,"elapsed":291,"user":{"displayName":"Mohammed Hamdan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7-0C4n1c_uDVPoywaYa91Jx17qP1YRlmJadqc=s64","userId":"00647759825092258022"}},"outputId":"448cdf83-b053-40d1-d01f-211a18f436b5"},"source":["len(trainloader_1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6250"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"Dbud90dyzSlI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KcjT2zhDzSlI"},"source":["## <font style=\"color:green\">2. Configuration [5 Points]</font>\n","\n","Define your configuration in this section.\n","\n","For example,\n","\n","```\n","@dataclass\n","class TrainingConfiguration:\n","    '''\n","    Describes configuration of the training process\n","    '''\n","    batch_size: int = 10 \n","    epochs_count: int = 50  \n","    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n","    log_interval: int = 5  \n","    test_interval: int = 1  \n","    data_root: str = \"/kaggle/input/pytorch-opencv-course-classification/\" \n","    num_workers: int = 2  \n","    device: str = 'cuda'  \n","    \n","```"]},{"cell_type":"code","metadata":{"id":"dDfWjOu9NKkS"},"source":["from typing import Callable, Iterable\n","from dataclasses import dataclass\n","from torchvision.transforms import ToTensor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UJyivF7zzSlI"},"source":["class TrainingConfiguration:\n","    '''\n","    Describes configuration of the training process\n","    '''\n","    batch_size: int = 10 \n","    epochs_count: int = 50  \n","    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n","    log_interval: int = 5  \n","    test_interval: int = 1  \n","    data_root: str = \"/content/drive/MyDrive/AI_OpenCV_PyTorch/Week7 - Project2: Kaggle Competition - Classification /dataset\" \n","    num_workers: int = 2  \n","    device: str = 'cuda'  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WFWyWVmbzSlJ"},"source":["class SystemConfig:\n","    seed: int = 42  # seed number to set the state of all random number generators\n","    cudnn_benchmark_enabled: bool = False  # enable CuDNN benchmark for the sake of performance\n","    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yH0X8dRQzSlJ"},"source":["class DatasetConfig:\n","    root_dir: str = \"data\"  # dataset directory root\n","    train_transforms: Iterable[Callable] = (\n","        ToTensor(),\n","    )  # data transformation to use during training data preparation\n","    test_transforms: Iterable[Callable] = (\n","        ToTensor(),\n","    )  # data transformation to use during test data preparation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lwSgGFdaNmVa"},"source":["class DataloaderConfig:\n","    batch_size: int = 250  # amount of data to pass through the network at each forward-backward iteration\n","    num_workers: int = 5  # number of concurrent processes using to prepare data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Z7-kELhNpqc"},"source":["class OptimizerConfig:\n","    learning_rate: float = 0.001  # determines the speed of network's weights update\n","    momentum: float = 0.9  # used to improve vanilla SGD algorithm and provide better handling of local minimas\n","    weight_decay: float = 0.0001  # amount of additional regularization on the weights values\n","    lr_step_milestones: Iterable = (\n","        30, 40\n","    )  # at which epoches should we make a \"step\" in learning rate (i.e. decrease it in some manner)\n","    lr_gamma: float = 0.1  # multiplier applied to current learning rate at each of lr_ctep_milestones"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EL4eglYcNwF9"},"source":["class TrainerConfig:\n","    model_dir: str = \"checkpoints\"  # directory to save model states\n","    model_saving_frequency: int = 1  # frequency of model state savings per epochs\n","    device: str = \"cpu\"  # device to use for training.\n","    epoch_num: int = 50  # number of times the whole dataset will be passed through the network\n","    progress_bar: bool = True  # enable progress bar visualization during train process"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cq8aomDgzSlJ"},"source":["## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n","\n","Define methods or classes that will be used in model evaluation, for example, accuracy, f1-score, etc."]},{"cell_type":"code","metadata":{"id":"bDQWn9yXzSlJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaSI8UQRzSlJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjNnYzj_zSlK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bGCVl5IRzSlK"},"source":["## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n","\n","Write the methods or classes that will be used for training and validation."]},{"cell_type":"code","metadata":{"id":"R30UiTuGN4y3"},"source":["\"\"\"Unified class to make training pipeline for deep neural networks.\"\"\"\n","import os\n","import datetime\n","from typing import Union, Callable\n","from pathlib import Path\n","from operator import itemgetter\n","import torch\n","from tqdm.auto import tqdm\n","from torch.optim.lr_scheduler import ReduceLROnPlateau"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHQ-y0SFzSlK"},"source":["def train(\n","    model,\n","    loader,\n","    loss_fn,\n","    optimizer,\n","    device,\n","    data_getter=itemgetter(\"image\"),\n","    target_getter=itemgetter(\"mask\"),\n","    iterator_type=tqdm,\n","    prefix=\"\",\n","    stage_progress=False\n","):\n","    model = model.train()\n","    iterator = iterator_type(loader, disable=not stage_progress, dynamic_ncols=True)\n","    loss_avg = AverageMeter()\n","    for i, sample in enumerate(iterator):\n","        optimizer.zero_grad()\n","        inputs = data_getter(sample).to(device)\n","        targets = target_getter(sample).to(device)\n","        predicts = model(inputs)\n","        loss = loss_fn(predicts, targets)\n","        loss.backward()\n","        optimizer.step()\n","        loss_avg.update(loss.item())\n","        status = \"{0}[Train][{1}] Loss_avg: {2:.5}, Loss: {3:.5}, LR: {4:.5}\".format(\n","            prefix, i, loss_avg.avg, loss_avg.val, optimizer.param_groups[0][\"lr\"]\n","        )\n","        iterator.set_description(status)\n","    return {\"loss\": loss_avg.avg}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TpEnfrS9zSlK"},"source":["def valid(\n","    model,\n","    loader,\n","    loss_fn,\n","    metric_fn,\n","    device,\n","    data_getter=itemgetter(\"image\"),\n","    target_getter=itemgetter(\"mask\"),\n","    iterator_type=tqdm,\n","    prefix=\"\",\n","    stage_progress=False,\n","    get_key_metric=itemgetter(\"accuracy\")\n","):\n","    model = model.eval()\n","    iterator = iterator_type(loader, disable=not stage_progress, dynamic_ncols=True)\n","    loss_avg = AverageMeter()\n","    metric_fn.reset()\n","    for i, sample in enumerate(iterator):\n","        inputs = data_getter(sample).to(device)\n","        targets = target_getter(sample).to(device)\n","        with torch.no_grad():\n","            predict = model(inputs)\n","            loss = loss_fn(predict, targets)\n","        loss_avg.update(loss.item())\n","        predict = predict.softmax(dim=1).detach()\n","        metric_fn.update_value(predict, targets)\n","        status = \"{0}[Test][{1}] Loss_avg: {2:.5}\".format(prefix, i, loss_avg.avg)\n","        if get_key_metric is not None:\n","            status = status + \", Metric_avg: {0:.5}\".format(get_key_metric(metric_fn.get_metric_value()))\n","        iterator.set_description(status)\n","    output = {\"metric\": metric_fn.get_metric_value(), \"loss\": loss_avg.avg}\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bgTyd_YXO5rO"},"source":["def end_epoch_classification(iterator, epoch, output_train, output_test):\n","    if hasattr(iterator, \"set_description\"):\n","        iterator.set_description(\n","            \"epoch: {0}, test_top1: {1:.5}, train_loss: {2:.5}, test_loss: {3:.5}\".format(\n","                epoch, output_test[\"metric\"][\"top1\"], output_train[\"loss\"], output_test[\"loss\"]\n","            )\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KK7TGcLPZ9r"},"source":["from abc import ABC, abstractmethod\n","class Visualizer(ABC):\n","    @abstractmethod\n","    def update_charts(self, train_metric, train_loss, test_metric, test_loss, learning_rate, epoch):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjBnTNe_PaV0"},"source":["class Trainer:  # pylint: disable=too-many-instance-attributes\n","\n","    def __init__( # pylint: disable=too-many-arguments\n","        self,\n","        model: torch.nn.Module,\n","        loader_train: torch.utils.data.DataLoader,\n","        loader_test: torch.utils.data.DataLoader,\n","        loss_fn: Callable,\n","        metric_fn: Callable,\n","        optimizer: torch.optim.Optimizer,\n","        lr_scheduler: Callable,\n","        device: Union[torch.device, str] = \"cuda\",\n","        model_saving_frequency: int = 1,\n","        save_dir: Union[str, Path] = \"checkpoints\",\n","        model_name_prefix: str = \"model\",\n","        data_getter: Callable = itemgetter(\"image\"),\n","        target_getter: Callable = itemgetter(\"target\"),\n","        stage_progress: bool = True,\n","        visualizer: Union[Visualizer, None] = None,\n","        get_key_metric: Callable = itemgetter(\"top1\"),\n","    ):\n","        self.model = model\n","        self.loader_train = loader_train\n","        self.loader_test = loader_test\n","        self.loss_fn = loss_fn\n","        self.metric_fn = metric_fn\n","        self.optimizer = optimizer\n","        self.lr_scheduler = lr_scheduler\n","        self.device = device\n","        self.model_saving_frequency = model_saving_frequency\n","        self.save_dir = save_dir\n","        self.model_name_prefix = model_name_prefix\n","        self.stage_progress = stage_progress\n","        self.data_getter = data_getter\n","        self.target_getter = target_getter\n","        self.hooks = {}\n","        self.visualizer = visualizer\n","        self.get_key_metric = get_key_metric\n","        self.metrics = {\"epoch\": [], \"train_loss\": [], \"test_loss\": [], \"test_metric\": []}\n","        self._register_default_hooks()\n","\n","    def fit(self, epochs):\n","        iterator = tqdm(range(epochs), dynamic_ncols=True)\n","        for epoch in iterator:\n","            output_train = self.hooks[\"train\"](\n","                self.model,\n","                self.loader_train,\n","                self.loss_fn,\n","                self.optimizer,\n","                self.device,\n","                prefix=\"[{}/{}]\".format(epoch, epochs),\n","                stage_progress=self.stage_progress,\n","                data_getter=self.data_getter,\n","                target_getter=self.target_getter\n","            )\n","            output_test = self.hooks[\"test\"](\n","                self.model,\n","                self.loader_test,\n","                self.loss_fn,\n","                self.metric_fn,\n","                self.device,\n","                prefix=\"[{}/{}]\".format(epoch, epochs),\n","                stage_progress=self.stage_progress,\n","                data_getter=self.data_getter,\n","                target_getter=self.target_getter,\n","                get_key_metric=self.get_key_metric\n","            )\n","            if self.visualizer:\n","                self.visualizer.update_charts(\n","                    None, output_train['loss'], output_test['metric'], output_test['loss'],\n","                    self.optimizer.param_groups[0]['lr'], epoch\n","                )\n","\n","            self.metrics['epoch'].append(epoch)\n","            self.metrics['train_loss'].append(output_train['loss'])\n","            self.metrics['test_loss'].append(output_test['loss'])\n","            self.metrics['test_metric'].append(output_test['metric'])\n","\n","            if self.lr_scheduler is not None:\n","                if isinstance(self.lr_scheduler, ReduceLROnPlateau):\n","                    self.lr_scheduler.step(output_train['loss'])\n","                else:\n","                    self.lr_scheduler.step()\n","\n","            if self.hooks[\"end_epoch\"] is not None:\n","                self.hooks[\"end_epoch\"](iterator, epoch, output_train, output_test)\n","\n","            if (epoch + 1) % self.model_saving_frequency == 0:\n","                os.makedirs(self.save_dir, exist_ok=True)\n","                torch.save(\n","                    self.model.state_dict(),\n","                    os.path.join(self.save_dir, self.model_name_prefix) + str(datetime.datetime.now())\n","                )\n","        return self.metrics\n","\n","    def register(self, hook_type, hook_fn):\n","        self.hooks[hook_type] = hook_fn\n","\n","    def _register_default(self):\n","        self.register_hook(\"train\", train_hook_default)\n","        self.register_hook(\"test\", test_hook_default)\n","        self.register_hook(\"end_epoch\", None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNWbmf_kzSlL"},"source":["## <font style=\"color:green\">5. Model [5 Points]</font>\n","\n","Define your model in this section.\n","\n","**You are allowed to use any pre-trained model.**"]},{"cell_type":"code","metadata":{"id":"m4qvRiMbzSlL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"13ko996SzSlL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJJL5wGEzSlL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ThZAJyhTzSlL"},"source":["## <font style=\"color:green\">6. Utils [5 Points]</font>\n","\n","Define your methods or classes which are not covered in the above sections."]},{"cell_type":"code","metadata":{"id":"e80aj8tHzSlL"},"source":["class AverageMeter:\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, count=1):\n","        self.val = val\n","        self.sum += val * count\n","        self.count += count\n","        self.avg = self.sum / self.count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0lzrjt9FzSlM"},"source":["def patch_configs(epoch_num_to_set=TrainerConfig.epoch_num, batch_size_to_set=DataloaderConfig.batch_size):\n","\n","    # default experiment params\n","    num_workers_to_set = DataloaderConfig.num_workers\n","\n","    if torch.cuda.is_available():\n","        device = \"cuda\"\n","    else:\n","        device = \"cpu\"\n","        batch_size_to_set = 16\n","        num_workers_to_set = 2\n","        epoch_num_to_set = 1\n","\n","    dataloader_config = DataloaderConfig(batch_size=batch_size_to_set, num_workers=num_workers_to_set)\n","    trainer_config = TrainerConfig(device=device, epoch_num=epoch_num_to_set)\n","    return dataloader_config, trainer_config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqXljTbczSlM"},"source":["def setup_system(system_config: SystemConfig) -> None:\n","    torch.manual_seed(system_config.seed)\n","    np.random.seed(system_config.seed)\n","    random.seed(system_config.seed)\n","    torch.set_printoptions(precision=10)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(system_config.seed)\n","        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n","        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic\n","\n","import matplotlib.pyplot as plt\n","\n","label_names = [\n","    'airplane',\n","    'automobile',\n","    'bird',\n","    'cat',\n","    'deer',\n","    'dog',\n","    'frog',\n","    'horse',\n","    'ship',\n","    'truck'\n","]\n","\n","\n","def plot_images(images, cls_true, cls_pred=None):\n","    \"\"\"\n","    Adapted from https://github.com/Hvass-Labs/TensorFlow-Tutorials/\n","    \"\"\"\n","    fig, axes = plt.subplots(3, 3)\n","\n","    for i, ax in enumerate(axes.flat):\n","        # plot img\n","        ax.imshow(images[i, :, :, :], interpolation='spline16')\n","\n","        # show true & predicted classes\n","        cls_true_name = label_names[cls_true[i]]\n","        if cls_pred is None:\n","            xlabel = \"{0} ({1})\".format(cls_true_name, cls_true[i])\n","        else:\n","            cls_pred_name = label_names[cls_pred[i]]\n","            xlabel = \"True: {0}\\nPred: {1}\".format(\n","                cls_true_name, cls_pred_name\n","            )\n","        ax.set_xlabel(xlabel)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VkqGp_0fzSlM"},"source":["## <font style=\"color:green\">7. Experiment [5 Points]</font>\n","\n","Choose your optimizer and LR-scheduler and use the above methods and classes to train your model."]},{"cell_type":"code","metadata":{"id":"SzVcyRhozSlM"},"source":["class Experiment:\n","    def __init__(\n","        self,system_config:  SystemConfig =SystemConfig(),\n","        dataset_config: DatasetConfig = DatasetConfig(),\n","        dataloader_config: DataloaderConfig = DataloaderConfig(),\n","        optimizer_config: OptimizerConfig = OptimizerConfig()\n","    ):\n","        self.loader_train, self.loader_test = get_data(\n","            batch_size=dataloader_config.batch_size,\n","            num_workers=dataloader_config.num_workers,\n","            data_root=dataset_config.root_dir\n","        )\n","        \n","        setup_system(system_config)\n","\n","        self.model = LeNet5()\n","        self.loss_fn = nn.CrossEntropyLoss()\n","        self.metric_fn = AccuracyEstimator(topk=(1, ))\n","        self.optimizer = optim.SGD(\n","            self.model.parameters(),\n","            lr=optimizer_config.learning_rate,\n","            weight_decay=optimizer_config.weight_decay,\n","            momentum=optimizer_config.momentum\n","        )\n","        self.lr_scheduler = MultiStepLR(\n","            self.optimizer, milestones=optimizer_config.lr_step_milestones, gamma=optimizer_config.lr_gamma\n","        )\n","        self.visualizer = TensorBoardVisualizer()\n","\n","    def run(self, trainer_config: TrainerConfig) -> dict:\n","\n","        device = torch.device(trainer_config.device)\n","        self.model = self.model.to(device)\n","        self.loss_fn = self.loss_fn.to(device)\n","\n","        model_trainer = Trainer(\n","            model=self.model,\n","            loader_train=self.loader_train,\n","            loader_test=self.loader_test,\n","            loss_fn=self.loss_fn,\n","            metric_fn=self.metric_fn,\n","            optimizer=self.optimizer,\n","            lr_scheduler=self.lr_scheduler,\n","            device=device,\n","            data_getter=itemgetter(0),\n","            target_getter=itemgetter(1),\n","            stage_progress=trainer_config.progress_bar,\n","            get_key_metric=itemgetter(\"top1\"),\n","            visualizer=self.visualizer,\n","            model_saving_frequency=trainer_config.model_saving_frequency,\n","            save_dir=trainer_config.model_dir\n","        )\n","\n","        model_trainer.register_hook(\"end_epoch\", hooks.end_epoch_hook_classification)\n","        self.metrics = model_trainer.fit(trainer_config.epoch_num)\n","        return self.metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pFuVsluzSlM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFOWw0jRzSlM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eqq4F13WzSlN"},"source":["## <font style=\"color:green\">8. TensorBoard Dev Scalars Log Link [5 Points]</font>\n","\n","Share your tensorboard scalars logs link in this section. You can also share (not mandatory) your GitHub link if you have pushed this project in GitHub. \n","\n","For example, [Find Project2 logs here](https://tensorboard.dev/experiment/kMJ4YU0wSNG0IkjrluQ5Dg/#scalars)."]},{"cell_type":"markdown","metadata":{"id":"u-1ipc2hzSlN"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"yCZwL3sjzSlN"},"source":["## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n","\n","Share your Kaggle profile link here with us so that we can give points for the competition score. \n","\n","You should have a minimum accuracy of `75%` on the test data to get all points. If accuracy is less than `70%`, you will not get any points for the section. \n","\n","**You must have to submit `submission.csv` (prediction for images in `test.csv`) in `Submit Predictions` tab in Kaggle to get any evaluation in this section.**"]},{"cell_type":"markdown","metadata":{"id":"66A7NnMQzSlN"},"source":[""]}]}